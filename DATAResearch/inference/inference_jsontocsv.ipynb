{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COCO file -> csv\n",
    "not yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import skimage.io as io\n",
    "import pylab\n",
    "import os\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 8.0)\n",
    "\n",
    "import os.path as osp\n",
    "import mmcv\n",
    "from mmcv import Config\n",
    "from mmdet.datasets import (build_dataloader, build_dataset, replace_ImageToTensor)\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import single_gpu_test\n",
    "from mmcv.runner import load_checkpoint\n",
    "from mmcv.parallel import MMDataParallel\n",
    "import pandas as pd\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "annotation file format <class 'list'> not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/opt/ml/baseline/level2-object-detection-level2-cv-19/DATAResearch/inference/inference_jsontocsv.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B101.101.216.82/opt/ml/baseline/level2-object-detection-level2-cv-19/DATAResearch/inference/inference_jsontocsv.ipynb#ch0000001vscode-remote?line=0'>1</a>\u001b[0m gt \u001b[39m=\u001b[39m []\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B101.101.216.82/opt/ml/baseline/level2-object-detection-level2-cv-19/DATAResearch/inference/inference_jsontocsv.ipynb#ch0000001vscode-remote?line=2'>3</a>\u001b[0m coco \u001b[39m=\u001b[39m COCO(\u001b[39m\"\u001b[39;49m\u001b[39mbest_predictions.json\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B101.101.216.82/opt/ml/baseline/level2-object-detection-level2-cv-19/DATAResearch/inference/inference_jsontocsv.ipynb#ch0000001vscode-remote?line=4'>5</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B101.101.216.82/opt/ml/baseline/level2-object-detection-level2-cv-19/DATAResearch/inference/inference_jsontocsv.ipynb#ch0000001vscode-remote?line=5'>6</a>\u001b[0m \u001b[39mimage id 별로 GT 값 추가 (여기서는 test.json을 사용하였기 때문에 GT가 없습니다.)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B101.101.216.82/opt/ml/baseline/level2-object-detection-level2-cv-19/DATAResearch/inference/inference_jsontocsv.ipynb#ch0000001vscode-remote?line=6'>7</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B101.101.216.82/opt/ml/baseline/level2-object-detection-level2-cv-19/DATAResearch/inference/inference_jsontocsv.ipynb#ch0000001vscode-remote?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m image_id \u001b[39min\u001b[39;00m coco\u001b[39m.\u001b[39mgetImgIds():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pycocotools/coco.py:83\u001b[0m, in \u001b[0;36mCOCO.__init__\u001b[0;34m(self, annotation_file)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/conda/lib/python3.8/site-packages/pycocotools/coco.py?line=80'>81</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(annotation_file, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     <a href='file:///opt/conda/lib/python3.8/site-packages/pycocotools/coco.py?line=81'>82</a>\u001b[0m     dataset \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[0;32m---> <a href='file:///opt/conda/lib/python3.8/site-packages/pycocotools/coco.py?line=82'>83</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mtype\u001b[39m(dataset)\u001b[39m==\u001b[39m\u001b[39mdict\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mannotation file format \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m not supported\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(dataset))\n\u001b[1;32m     <a href='file:///opt/conda/lib/python3.8/site-packages/pycocotools/coco.py?line=83'>84</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mDone (t=\u001b[39m\u001b[39m{:0.2f}\u001b[39;00m\u001b[39ms)\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(time\u001b[39m.\u001b[39mtime()\u001b[39m-\u001b[39m tic))\n\u001b[1;32m     <a href='file:///opt/conda/lib/python3.8/site-packages/pycocotools/coco.py?line=84'>85</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset \u001b[39m=\u001b[39m dataset\n",
      "\u001b[0;31mAssertionError\u001b[0m: annotation file format <class 'list'> not supported"
     ]
    }
   ],
   "source": [
    "gt = []\n",
    "\n",
    "coco = COCO(\"best_predictions.json\")\n",
    "   \n",
    "'''\n",
    "image id 별로 GT 값 추가 (여기서는 test.json을 사용하였기 때문에 GT가 없습니다.)\n",
    "'''\n",
    "for image_id in coco.getImgIds():\n",
    "        \n",
    "    image_info = coco.loadImgs(image_id)[0]\n",
    "    annotation_id = coco.getAnnIds(imgIds=image_info['id'])\n",
    "    annotation_info_list = coco.loadAnns(annotation_id)\n",
    "        \n",
    "    file_name = image_info['file_name']\n",
    "        \n",
    "    for annotation in annotation_info_list:\n",
    "        gt.append([file_name, annotation['category_id'],\n",
    "                    float(annotation['socre']),\n",
    "                    float(annotation['bbox'][0]),\n",
    "                    float(annotation['bbox'][0]) + float(annotation['bbox'][2]),\n",
    "                    float(annotation['bbox'][1]),\n",
    "                    (float(annotation['bbox'][1]) + float(annotation['bbox'][3]))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## JSON -> Pandas -> CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"/opt/ml/baseline/level2-object-detection-level2-cv-19/yolov5/runs/val/exp3/best_predictions.json\")\n",
    "data.sort_values(by=[\"image_id\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = data.iloc[0].image_id\n",
    "\n",
    "inf_dict = {\"PredictionString\":[],\"image_id\":[]}\n",
    "\n",
    "PredictionString = \"\"\n",
    "for i in data.iterrows():\n",
    "    if(flag != i[1].image_id):\n",
    "        inf_dict[\"PredictionString\"].append(PredictionString)\n",
    "        inf_dict[\"image_id\"].append(\"test/\" + str(10000 + flag)[1:] + \".jpg\")\n",
    "        PredictionString = \"\"\n",
    "        flag = i[1].image_id\n",
    "        \n",
    "        # if(i[1].image_id == 5):\n",
    "        #     break\n",
    "\n",
    "    #set score threshold\n",
    "    if(i[1].score < 0.001):\n",
    "        continue\n",
    "\n",
    "    add_list = [i[1].category_id, i[1].score, i[1].bbox[1], i[1].bbox[2], i[1].bbox[3]]\n",
    "    add_list = list(map(str,add_list))\n",
    "    for i in add_list:\n",
    "        PredictionString += i + \" \"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(inf_dict).to_csv('./test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
