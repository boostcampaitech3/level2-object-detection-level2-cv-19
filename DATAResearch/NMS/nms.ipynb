{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import skimage.io as io\n",
    "import pylab\n",
    "import os\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 8.0)\n",
    "\n",
    "import os.path as osp\n",
    "import mmcv\n",
    "from mmcv import Config\n",
    "from mmdet.datasets import (build_dataloader, build_dataset, replace_ImageToTensor)\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import single_gpu_test\n",
    "from mmcv.runner import load_checkpoint\n",
    "from mmcv.parallel import MMDataParallel\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "import torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 사용한 val_fold json file 경로\n",
    "GT_JSON = '/opt/ml/baseline/level2-object-detection-level2-cv-19/DATAResearch/inference/serverbase_submission.json'\n",
    "\n",
    "LABEL_NAME = [\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \n",
    "              \"Glass\", \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test/1472.jpg'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_info = coco.loadImgs(1472)[0]\n",
    "image_info['file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_id = coco.getAnnIds(imgIds=image_info['id'])\n",
    "annotation_info_list = coco.loadAnns(annotation_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image_id': 1472,\n",
       "  'category_id': 0,\n",
       "  'score': 0.15437564253807068,\n",
       "  'area': 225213.65132496133,\n",
       "  'bbox': [348.12213134765625,\n",
       "   203.8895263671875,\n",
       "   306.01495361328125,\n",
       "   735.9563598632812],\n",
       "  'iscrowd': 0,\n",
       "  'id': 35419},\n",
       " {'image_id': 1472,\n",
       "  'category_id': 9,\n",
       "  'score': 0.1185765340924263,\n",
       "  'area': 209563.41015301272,\n",
       "  'bbox': [352.02703857421875,\n",
       "   205.22866821289062,\n",
       "   292.3814697265625,\n",
       "   716.7465515136719],\n",
       "  'iscrowd': 0,\n",
       "  'id': 35420},\n",
       " {'image_id': 1472,\n",
       "  'category_id': 1,\n",
       "  'score': 0.06453073769807816,\n",
       "  'area': 219378.81796425395,\n",
       "  'bbox': [350.3594970703125,\n",
       "   212.96823120117188,\n",
       "   302.94305419921875,\n",
       "   724.1585998535156],\n",
       "  'iscrowd': 0,\n",
       "  'id': 35421}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.24s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "gt = []\n",
    "\n",
    "coco = COCO(GT_JSON)\n",
    "   \n",
    "'''\n",
    "image id 별로 GT 값 추가 (여기서는 test.json을 사용하였기 때문에 GT가 없습니다.)\n",
    "'''\n",
    "for image_id in coco.getImgIds():\n",
    "        \n",
    "    image_info = coco.loadImgs(image_id)[0]\n",
    "    annotation_id = coco.getAnnIds(imgIds=image_info['id'])\n",
    "    annotation_info_list = coco.loadAnns(annotation_id)\n",
    "        \n",
    "    file_name = image_info['file_name']\n",
    "        \n",
    "    for annotation in annotation_info_list:\n",
    "        gt.append([file_name, annotation['category_id'],\n",
    "                    float(annotation['score']),\n",
    "                    float(annotation['bbox'][0]),\n",
    "                    float(annotation['bbox'][0]) + float(annotation['bbox'][2]),\n",
    "                    float(annotation['bbox'][1]),\n",
    "                    (float(annotation['bbox'][1]) + float(annotation['bbox'][3]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_list = [0]\n",
    "flag = gt[0][0]\n",
    "\n",
    "for i, v in enumerate(gt):\n",
    "    if flag == v[0]:\n",
    "        continue\n",
    "    else:\n",
    "        i_list.append(i)\n",
    "        flag = v[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(boxes_preds, boxes_labels, box_format='corners'):\n",
    "    '''\n",
    "    Calculates intersection over union\n",
    "    \n",
    "    Parameters:\n",
    "        boxes_preds (tensor): Predictions of Bounding Boxes  (BATCH_SIZE, 4)\n",
    "        boxes_labels (tensor): Correct labels of Bounding Boxes  (BATCH_SIZE, 4)\n",
    "        box_format (str): midpoint/corners, if boxes (x,y,w,h) or (x1,y1,x2,y2)\n",
    "    \n",
    "    Returns:\n",
    "        tensor: Intersection over union for all examples\n",
    "    ''' \n",
    "    \n",
    "    if box_format == 'midpoint':\n",
    "        box1_x1 = boxes_preds[:,0:1] - boxes_preds[:,2:3] / 2\n",
    "        box1_y1 = boxes_preds[:,1:2] - boxes_preds[:,3:4] / 2\n",
    "        box1_x2 = boxes_preds[:,0:1] + boxes_preds[:,2:3] / 2\n",
    "        box1_y2 = boxes_preds[:,1:2] + boxes_preds[:,3:4] / 2\n",
    "\n",
    "        box2_x1 = boxes_labels[:,0:1] - boxes_labels[:,2:3] / 2\n",
    "        box2_y1 = boxes_labels[:,1:2] - boxes_labels[:,3:4] / 2\n",
    "        box2_x2 = boxes_labels[:,0:1] + boxes_labels[:,2:3] / 2\n",
    "        box2_y2 = boxes_labels[:,1:2] + boxes_labels[:,3:4] / 2\n",
    "    \n",
    "    elif box_format == 'corners':   \n",
    "        box1_x1 = boxes_preds[:,0:1]\n",
    "        box1_y1 = boxes_preds[:,1:2]\n",
    "        box1_x2 = boxes_preds[:,2:3]\n",
    "        box1_y2 = boxes_preds[:,3:4]\n",
    "\n",
    "        box2_x1 = boxes_labels[:,0:1]\n",
    "        box2_y1 = boxes_labels[:,1:2]\n",
    "        box2_x2 = boxes_labels[:,2:3]\n",
    "        box2_y2 = boxes_labels[:,3:4]\n",
    "        \n",
    "    x1 = torch.max(box1_x1, box2_x1)\n",
    "    y1 = torch.max(box1_y1, box2_y1)\n",
    "    x2 = torch.min(box1_x2, box2_x2)\n",
    "    y2 = torch.min(box1_y2, box2_y2)\n",
    "    \n",
    "    # .clamp(0) is for the case when they do not intersect\n",
    "    intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n",
    "    \n",
    "    box1_area = abs((box1_x2 - box1_x1) * (box1_y1 - box1_y2))\n",
    "    box2_area = abs((box2_x2 - box2_x1) * (box2_y1 - box2_y2))\n",
    "    \n",
    "    return intersection / (box1_area + box2_area - intersection + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(bboxes, iou_threshold, prob_threshold, box_format='corners'):\n",
    "    # bboxes = [[1, 0.9, x1, y1, x2, y2],[],[]...]\n",
    "    #        = [class_prediction, probability_score, x1, y1, x2, y2]\n",
    "    \n",
    "    #assert type(predictions) == list\n",
    "    \n",
    "    bboxes = [box for box in bboxes if box[1] > prob_threshold]\n",
    "    bboxes = sorted(bboxes, key=lambda x: x[1], reverse=True)\n",
    "    bboxes_after_nms = []\n",
    "    \n",
    "    while bboxes:\n",
    "        chosen_box = bboxes.pop(0)\n",
    "        \n",
    "        bboxes = [box for box in bboxes \n",
    "                  if box[0] != chosen_box[0] \n",
    "                  or intersection_over_union(torch.Tensor(chosen_box[2:]).view(1,-1),\n",
    "                                      torch.Tensor(box[2:]).view(1,-1),\n",
    "                                      box_format=box_format) < iou_threshold]\n",
    "        \n",
    "        bboxes_after_nms.append(chosen_box)\n",
    "        \n",
    "    return bboxes_after_nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PredictionString</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7 0.998166561126709 219.02938842773438 455.630...</td>\n",
       "      <td>test/0000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 0.919633686542511 340.2513122558594 757.7150...</td>\n",
       "      <td>test/0001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 0.9743971824645996 289.17340087890625 997.43...</td>\n",
       "      <td>test/0002.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9 0.98899906873703 166.99288940429688 883.6703...</td>\n",
       "      <td>test/0003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9 0.5510952472686768 443.4324951171875 658.492...</td>\n",
       "      <td>test/0004.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    PredictionString       image_id\n",
       "0  7 0.998166561126709 219.02938842773438 455.630...  test/0000.jpg\n",
       "1  3 0.919633686542511 340.2513122558594 757.7150...  test/0001.jpg\n",
       "2  1 0.9743971824645996 289.17340087890625 997.43...  test/0002.jpg\n",
       "3  9 0.98899906873703 166.99288940429688 883.6703...  test/0003.jpg\n",
       "4  9 0.5510952472686768 443.4324951171875 658.492...  test/0004.jpg"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_strings = []\n",
    "file_names = []\n",
    "\n",
    "for i in range(len(i_list)):\n",
    "    if(i == len(i_list)-2):\n",
    "        break\n",
    "    file = gt[i_list[i]][0]\n",
    "    bbox = [i[1:] for i in gt[i_list[i]:i_list[i+1]]]\n",
    "    new_box = non_max_suppression(bbox, 0.5, 0.3)\n",
    "    prediction_string = ''\n",
    "    for i in new_box:\n",
    "        prediction_string += str(i[0]) + ' ' + str(i[1]) + ' ' + str(i[2]) + ' ' + str(i[3]) + ' ' + str(\n",
    "                    i[4]) + ' ' + str(i[5]) + ' '\n",
    "    prediction_strings.append(prediction_string)\n",
    "    file_names.append(file)\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['PredictionString'] = prediction_strings\n",
    "submission['image_id'] = file_names\n",
    "submission.to_csv('nms.csv', index=None)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4869"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(i_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f5d7164c64e63af887b53f785b7c056834a1b06812e2ab286d66941e0de4c0dd"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('mmdet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
